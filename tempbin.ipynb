{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "\n",
    "imputer_knn = KNNImputer(n_neighbors=5)\n",
    "\n",
    "train_num = training_set.select_dtypes(include=[np.number])\n",
    "valid_num = validation_set.select_dtypes(include=[np.number])\n",
    "\n",
    "train_cat = training_set.select_dtypes(include=object)\n",
    "valid_cat = validation_set.select_dtypes(include=object)\n",
    "\n",
    "SimpleImputer(strategy='most_frequent').fit_transform(train_cat)\n",
    "SimpleImputer(strategy='most_frequent').fit_transform(valid_cat)\n",
    "\n",
    "\n",
    "training_imputed[train_num]  = KNNImputer(n_neighbors=5).fit_transform(train_num)\n",
    "validation_imputed[valid_num] = KNNImputer(n_neighbors=5).fit_transform(valid_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.drop(columns={'Country','Thinness 10-19 Years','Under-Five Deaths','Schooling'})\n",
    "test_set = test_set.drop(columns={'Country','Thinness 10-19 Years','Under-Five Deaths','Schooling'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "\n",
    "class ColumnDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        return X.drop(columns=self.columns, axis=1)\n",
    "\n",
    "# Create an instance of the transformer\n",
    "dropper = ColumnDropper(columns=['Country','Thinness 10-19 Years','Under-Five Deaths','Schooling'])\n",
    "\n",
    "# Apply the transformer to a DataFrame\n",
    "#X_transformed = dropper.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation and Standardization\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"dropper\", ColumnDropper(columns=['Thinness 10-19 Years','Under-Five Deaths','Schooling'])),\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"standardize\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"dropper\", ColumnDropper(columns=['Country'])),\n",
    "    (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"label_encoder\", FunctionTransformer(LabelEncoder().fit_transform)),\n",
    "    (\"reshape\", FunctionTransformer(lambda x: x.reshape(-1,1), validate=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error = 2.84\n",
      "Mean squared error = 15.62\n",
      "Median absolute error = 1.95\n",
      "Explain variance score = 0.84\n",
      "R2 score = 0.84\n"
     ]
    }
   ],
   "source": [
    "X1 = X_train[['Infant Deaths']]\n",
    "X2 = X_valid[['Infant Deaths']]\n",
    "\n",
    "lr_temp = make_pipeline(preprocessing, LinearRegression())\n",
    "lr_temp.fit(X1,y_train)\n",
    "\n",
    "\n",
    "y_valid_pred = lr_temp.predict(X_valid_selected) \n",
    "\n",
    "print(\"Mean absolute error =\", round(mean_absolute_error(y_valid, y_valid_pred), 2)) \n",
    "print(\"Mean squared error =\", round(mean_squared_error(y_valid, y_valid_pred), 2)) \n",
    "print(\"Median absolute error =\", round(median_absolute_error(y_valid, y_valid_pred), 2)) \n",
    "print(\"Explain variance score =\", round(explained_variance_score(y_valid, y_valid_pred), 2)) \n",
    "print(\"R2 score =\", round(r2_score(y_valid, y_valid_pred), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = X_train['Status']\n",
    "w_multi = np.array([0 if x=='Developing' else 1 for x in w])\n",
    "\n",
    "w_v = X_valid['Status']\n",
    "w_multi_v = np.array([0 if x=='Developing' else 1 for x in w_v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE using S-Learner with LinearRegression: 66.05561\n",
      "RMSE using T-Learner with XGBRegressor: 63.86639\n",
      "RMSE using X-Learner with XGBRegressor: 67.71821\n",
      "RMSE using R-Learner with XGBRegressor: 71\n"
     ]
    }
   ],
   "source": [
    "# Ready-to-use S-Learner using LinearRegression\n",
    "learner_s = LRSRegressor(control_name='control')\n",
    "learner_s.fit(X_c, w_multi, y_c)\n",
    "pred_s = learner_s.predict(X_v, w_multi_v)\n",
    "error_s = mean_squared_error(pred_s, y_v)**(1/2) #np.mean(np.abs(pred_s - y_v))\n",
    "print('RMSE using S-Learner with LinearRegression: {}'.format(round(error_s,5)))\n",
    "\n",
    "# Ready-to-use T-Learner using XGBTRegressor\n",
    "learner_t = BaseTRegressor(learner=XGBRegressor(),control_name='control')\n",
    "learner_t.fit(X_c, w_multi, y_c)\n",
    "pred_t = learner_t.predict(X_v, w_multi_v)\n",
    "error_t = mean_squared_error(pred_t, y_v)**(1/2) #np.mean(np.abs(pred_t - y_v))\n",
    "print('RMSE using T-Learner with XGBRegressor: {}'.format(round(error_t,5)))\n",
    "\n",
    "# X Learner without propensity score input\n",
    "learner_x = BaseXRegressor(learner=XGBRegressor(),control_name='control')\n",
    "learner_x.fit(X_c, w_multi, y_c)\n",
    "pred_x = learner_x.predict(X_v, w_multi_v)\n",
    "error_x = mean_squared_error(pred_x, y_v)**(1/2) #np.mean(np.abs(pred_x - y_v))\n",
    "print('RMSE using X-Learner with XGBRegressor: {}'.format(round(error_x,5)))\n",
    "\n",
    "# R Learner without propensity score input\n",
    "learner_r = BaseRRegressor(learner = XGBRegressor(),control_name='control')\n",
    "learner_r.fit(X_c, w_multi, y_c)\n",
    "pred_r = learner_r.predict(X_v, w_multi_v)\n",
    "error_r = mean_squared_error(pred_r, y_v)**(1/2) #np.mean(np.abs(pred_r - y_v))\n",
    "print('RMSE using R-Learner with XGBRegressor: {}'.format(round(error_r),5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Root Mean Squared Error (RMSE) is a common measure of the performance of a regression model. A lower RMSE value indicates a better fit of the model to the data.\n",
    "\n",
    "Based on the results, we can conclude that the T-Learner with XGBRegressor has the best fit to the data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb8d3085d426e5e8dee3252ffbadecffc2a8c816985f9d79249a1de42c265c0a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
